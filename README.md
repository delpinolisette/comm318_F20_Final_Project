## My final project for COMM318 _Stories from Data_ (Fall2020)

* You will edit this file to act as the main index page for your project 


  
### Directory:
```
├───data
│   ├───processed
│   └───raw
├───data_analysis
│   ├───.ipynb_checkpoints
│   └───scraping
│       ├───.ipynb_checkpoints
│       └───__pycache__
└───data_story_presentation
```

`data`: folder keeping track of both raw and cleaned up data sets. 
`data_analysis`: folder keeping track of analyses of all data sets. It has a lot of content, check it out!!
`data_analysis/scraping`: keeps track of python modules written to aid with scraping using PRAW and Reddit API. 
``


### Extra: What I've Learned:

- In this project, I learned:
    - how to use PRAW to scrape subreddits
    - how to store a secret key
    - how to create a csv from data frames, and vice versa


### Project Management 
Since Github renders to do lists now, going to list tasks here:

- [x] Scrape data for `CSCareerQuestions` subreddit and convert dates
- [x] Scrape data for newest `Jobs` data and convert dates
- [x] Scrape data for  `CareerGuidance` subreddit and convert dates
- [x] Scrape data for `ExperiencedDevs` subreddit and convert dates
- [ ] Perform data analysis on jobs dataset 
  - [ ] dimensions + subsetting by month + filter to highest comments + filter to average comment + median scores (to compare others to) + highlight the most important post from each month + highlight the most important post overall
- [ ] Perform data analysis on careerguidance dataset
- [ ] curate data story some more


### Sources and Links 

